# -*- coding: utf-8 -*-
"""CS419_Project_Code

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1juY5UsoR5z3MwxAeCF4aHtdvOK1LCi46

## Importing Libraries and Datasets
"""

# General Libraries
import numpy as np
import pandas as pd
import plotly.express as px
import matplotlib.pyplot as plt
from tabulate import tabulate
import seaborn as sns

# Machine Learning
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from sklearn.metrics import f1_score

# ! git clone https://github.com/bhavini-jeloka/cs419-poker.git

# ! pwd # should be content

"""## Loading Datasets"""

# %cd cs419-poker

training_data =  pd.read_csv("poker-hand-training-true.data", header=None, sep=",")
testing_data =  pd.read_csv("poker-hand-testing.data", header=None, sep=",")

testing_data.head()

training_data.hist(column=10)
x = [i for i in range(0,10)]
labels = ['Nothing in hand','1 pair','2 pairs','3 of a kind','Straight','Flush','Full house','Four of a kind','Straight flush','Royal flush']
plt.title('Class Distribution')
plt.xlabel('Poker Hand Label')
plt.xticks(x)
plt.ylabel('Number of occurences')

testing_data.hist(column=10)
plt.title('Class Distribution')
plt.xlabel('Poker Hand Label')
plt.xticks(x)
plt.ylabel('Number of occurences')

"""## Getting labeled features and target variables"""

scaler=MinMaxScaler()
def get_labeled_features(data_frame):
  
    last_col = list(data_frame.columns)[-1]
    phi = data_frame.drop(columns = [last_col]).copy()
    y = data_frame[last_col]

    scaler.fit(phi)
    phi = scaler.transform(phi)

    return phi,y

"""## Hyperparameter Tuning for Selecting the Best Model"""

X, Y= get_labeled_features(training_data)

"""### SVM Classifier"""

# SVM classifier
from sklearn.svm import SVC
model_SVMC = SVC(max_iter=2000)

params={'kernel':['poly', 'rbf', 'sigmoid'], 
        'C':[1.25,1.3,1.35, 1.4, 1.45, 1.5],
        }
gs=GridSearchCV(estimator=model_SVMC, param_grid=params, cv=3)
gs = gs.fit(X, Y)
best_params=gs.best_params_
accuracy=gs.best_score_
print(best_params, accuracy)

"""*Best Result : {'kernel': 'rbf','C': 1.45} 0.5409*

### Logistic Regression
"""

# logistic regression
from sklearn.linear_model import LogisticRegression
model_LR = LogisticRegression(max_iter=1000)

params={'C':[0.032,0.033,0.034,0.035,0.036] 
         }
gs=GridSearchCV(estimator=model_LR, param_grid=params, cv=3)
gs = gs.fit(X, Y)
best_params=gs.best_params_
accuracy=gs.best_score_
print(best_params, accuracy)

"""*Best Result : {'C': 0.032} 0.4994*

### MLP Classifier

1. Comparing number of layers for MLP classifier
"""

# neural networks
from sklearn.neural_network import MLPClassifier
model_NN_C = MLPClassifier(random_state=1, max_iter=2000)

params={'hidden_layer_sizes':[(10),(10,10),(10,10,10)], 
        'activation':['relu','tanh'],
        'alpha':[0.0001, 0.001],
        }
gs=GridSearchCV(estimator=model_NN_C, param_grid=params, cv=3)
gs = gs.fit(X, Y)
best_params=gs.best_params_
accuracy=gs.best_score_
print(best_params, accuracy)

"""*Best Result:  {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10, 10, 10)} 0.5788883265643348*

2. Checking for complex model
"""

from sklearn.neural_network import MLPClassifier
model_NN_C = MLPClassifier(random_state=1, max_iter=2000)

params={'hidden_layer_sizes':[(100,100,100)], 
        'activation':['relu'],
        'alpha':[0.0001],
        }
gs=GridSearchCV(estimator=model_NN_C, param_grid=params, cv=3)
gs = gs.fit(X, Y)
best_params=gs.best_params_
accuracy=gs.best_score_
print(best_params, accuracy)

"""*Result : {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 100, 100)} 0.5983598118938991*

3. Comparing different number of neurons for MLP Classifier
"""

from sklearn.neural_network import MLPClassifier
model_NN_C = MLPClassifier(random_state=1, max_iter=3000)

params={'hidden_layer_sizes':[(64,64),(75,75),(85,85),(100,100)], 
        'activation':['relu','tanh'],
        'alpha':[0.0001],
        }
gs=GridSearchCV(estimator=model_NN_C, param_grid=params, cv=3)
gs = gs.fit(X, Y)
best_params=gs.best_params_
accuracy=gs.best_score_
print(best_params, accuracy)

"""*Best Result: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (64, 64)} 0.9774890123201837*"""

print(gs.cv_results_['params']['mean_test_score'])

data = {'Neural Networks':0.9775, 'Support Vector Classification ':0.5409, 'Logistic Regression':0.4972}
Models = list(data.keys())
Accuracies = list(data.values())
  
fig = plt.figure(figsize = (10, 5))

plt.bar(Models, Accuracies, color ='maroon',
        width = 0.4)
 
plt.xlabel("Models")
plt.ylabel("Accuracies")
plt.title("Accuracies Across Different Models")
plt.show()

labelss = ["(10,10,10)","(100,100,100)","(64,64)",]
accuracy = [0.5789,0.5984,0.9775]

plt.bar(labelss,accuracy)
plt.title('Comparison of different models')
plt.xlabel('Models')
plt.ylabel('Accuracy')

"""### Deploying the Model"""

last_col = list(testing_data.columns)[-1]
X_test = testing_data.drop(columns = [last_col]).copy()
X_test = scaler.transform(X_test)
Y_test = testing_data[last_col]

# final model
from sklearn.neural_network import MLPClassifier
model_NN_C = MLPClassifier(activation='tanh', alpha=0.0001, hidden_layer_sizes=(64,64), random_state=1, max_iter=3000)
model_NN_C.fit(X, Y)
Y_pred = model_NN_C.predict(X_test)
print('Mean Squared Error (Test Set) %.2f'% mean_squared_error(Y_test, Y_pred,squared=False)) 
print(Y_pred)
print('F1 score (Test Set):%.2f'% f1_score(Y_test, Y_pred, average='macro'))

"""Mean Squared Error (Test Set) 0.40
[0 1 1 ... 1 1 2]
F1 score (Test Set):0.44
"""

# from google.colab import drive
# drive.mount('/content/drive')

from sklearn.metrics import classification_report
from pprint import pprint as pp
pp(classification_report(Y_test,Y_pred,))

"""('              precision    recall  f1-score   support\n'
 '\n'
 '           0       0.99      1.00      0.99    501209\n'
 '           1       1.00      1.00      1.00    422498\n'
 '           2       0.95      0.96      0.96     47622\n'
 '           3       0.85      0.85      0.85     21121\n'
 '           4       0.33      0.10      0.15      3885\n'
 '           5       0.45      0.26      0.33      1996\n'
 '           6       0.21      0.12      0.15      1424\n'
 '           7       0.00      0.00      0.00       230\n'
 '           8       0.00      0.00      0.00        12\n'
 '           9       0.00      0.00      0.00         3\n'
 '\n'
 '    accuracy                           0.99   1000000\n'
 '   macro avg       0.48      0.43      0.44   1000000\n'
 'weighted avg       0.98      0.99      0.99   1000000\n')
"""